{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 29: Unsupervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.master(\"local\").appName(\"Chapter29\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+-----------+\n",
      "|InvoiceNo|StockCode|         Description|Quantity|        InvoiceDate|UnitPrice|CustomerID|       Country|   features|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+-----------+\n",
      "|   580538|    23084|  RABBIT NIGHT LIGHT|      48|2011-12-05 08:38:00|     1.79|   14075.0|United Kingdom|[1.79,48.0]|\n",
      "|   580538|    23077| DOUGHNUT LIP GLOSS |      20|2011-12-05 08:38:00|     1.25|   14075.0|United Kingdom|[1.25,20.0]|\n",
      "|   580538|    22906|12 MESSAGE CARDS ...|      24|2011-12-05 08:38:00|     1.65|   14075.0|United Kingdom|[1.65,24.0]|\n",
      "|   580538|    21914|BLUE HARMONICA IN...|      24|2011-12-05 08:38:00|     1.25|   14075.0|United Kingdom|[1.25,24.0]|\n",
      "|   580538|    22467|   GUMBALL COAT RACK|       6|2011-12-05 08:38:00|     2.55|   14075.0|United Kingdom| [2.55,6.0]|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "va = VectorAssembler(inputCols=['UnitPrice', 'Quantity'], outputCol='features')\n",
    "sales = va.transform(spark.read.format(\"csv\")\\\n",
    "                           .option(\"header\", \"True\")\\\n",
    "                           .option(\"inferSchema\", \"True\")\\\n",
    "                           .load(\"../data/retail-data/by-day/*.csv\")\\\n",
    "                           .limit(50).coalesce(1).where(\"Description IS NOT NULL\"))\n",
    "sales.cache()\n",
    "sales.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "featuresCol: features column name. (default: features)\n",
      "initMode: The initialization algorithm. This can be either \"random\" to choose random points as initial cluster centers, or \"k-means||\" to use a parallel variant of k-means++ (default: k-means||)\n",
      "initSteps: The number of steps for k-means|| initialization mode. Must be > 0. (default: 2)\n",
      "k: The number of clusters to create. Must be > 1. (default: 2, current: 5)\n",
      "maxIter: max number of iterations (>= 0). (default: 20)\n",
      "predictionCol: prediction column name. (default: prediction)\n",
      "seed: random seed. (default: 2896968671297020976)\n",
      "tol: the convergence tolerance for iterative algorithms (>= 0). (default: 0.0001)\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.clustering import KMeans\n",
    "\n",
    "km = KMeans(k=5)\n",
    "print(km.explainParams())\n",
    "kmModel = km.fit(sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster sizes = [10, 20, 5, 12, 3]\n",
      "KMeans model cost = 273.6364283333328\n",
      "Centers = [array([ 0.956, 23.2  ]), array([4.5965, 4.55  ]), array([13.04,  2.4 ]), array([ 1.1       , 11.33333333]), array([ 1.16333333, 44.        ])]\n"
     ]
    }
   ],
   "source": [
    "print(\"Cluster sizes = {}\".format(kmModel.summary.clusterSizes))\n",
    "print(\"KMeans model cost = {}\".format(kmModel.computeCost(sales)))\n",
    "print(\"Centers = {}\".format(kmModel.clusterCenters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bisecting K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "featuresCol: features column name. (default: features)\n",
      "k: The desired number of leaf clusters. Must be > 1. (default: 4, current: 5)\n",
      "maxIter: max number of iterations (>= 0). (default: 20, current: 5)\n",
      "minDivisibleClusterSize: The minimum number of points (if >= 1.0) or the minimum proportion of points (if < 1.0) of a divisible cluster. (default: 1.0)\n",
      "predictionCol: prediction column name. (default: prediction)\n",
      "seed: random seed. (default: 5498043195691022326)\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.clustering import BisectingKMeans\n",
    "\n",
    "bkm = BisectingKMeans(k=5, maxIter=5)\n",
    "print(bkm.explainParams())\n",
    "bkmModel = bkm.fit(sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster sizes = [17, 10, 10, 10, 3]\n",
      "KMeans model cost = 298.17485078431366\n",
      "Centers = [array([3.55176471, 5.41176471]), array([ 0.93, 12.  ]), array([10.065,  2.7  ]), array([ 0.956, 23.2  ]), array([ 1.16333333, 44.        ])]\n"
     ]
    }
   ],
   "source": [
    "print(\"Cluster sizes = {}\".format(bkmModel.summary.clusterSizes))\n",
    "print(\"KMeans model cost = {}\".format(bkmModel.computeCost(sales)))\n",
    "print(\"Centers = {}\".format(bkmModel.clusterCenters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Mixture Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "featuresCol: features column name. (default: features)\n",
      "k: Number of independent Gaussians in the mixture model. Must be > 1. (default: 2, current: 5)\n",
      "maxIter: max number of iterations (>= 0). (default: 100)\n",
      "predictionCol: prediction column name. (default: prediction)\n",
      "probabilityCol: Column name for predicted class conditional probabilities. Note: Not all models output well-calibrated probability estimates! These probabilities should be treated as confidences, not precise probabilities. (default: probability)\n",
      "seed: random seed. (default: -2238121618897628805)\n",
      "tol: the convergence tolerance for iterative algorithms (>= 0). (default: 0.01)\n"
     ]
    }
   ],
   "source": [
    "# note that you should import \"Gaussian Mixture\" and not \"Gaussian Mixture Model\", that's the model after the fit\n",
    "from pyspark.ml.clustering import GaussianMixture\n",
    "\n",
    "gmm = GaussianMixture(k=5)\n",
    "print(gmm.explainParams())\n",
    "gmmModel = gmm.fit(sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model weights = [0.3764628488521458, 0.06003637026340386, 0.1999636297366328, 0.1999999999095532, 0.16353715123826437]\n",
      "+--------------------+--------------------+\n",
      "|                mean|                 cov|\n",
      "+--------------------+--------------------+\n",
      "|[3.73111693575823...|1.411795180927723...|\n",
      "|[1.16290775444429...|0.196554200997605...|\n",
      "|[0.95609006359898...|0.242797910224151...|\n",
      "|[0.93000000003671...|0.324399999992557...|\n",
      "|[11.1043458644732...|6.691868107826227...|\n",
      "+--------------------+--------------------+\n",
      "\n",
      "+----------+\n",
      "|prediction|\n",
      "+----------+\n",
      "|         1|\n",
      "|         2|\n",
      "|         2|\n",
      "|         2|\n",
      "|         0|\n",
      "|         1|\n",
      "|         0|\n",
      "|         2|\n",
      "|         0|\n",
      "|         0|\n",
      "+----------+\n",
      "only showing top 10 rows\n",
      "\n",
      "Cluster sizes = [19, 3, 10, 10, 8]\n",
      "[Row(probability=DenseVector([0.0, 1.0, 0.0, 0.0, 0.0])), Row(probability=DenseVector([0.0, 0.0, 1.0, 0.0, 0.0])), Row(probability=DenseVector([0.0, 0.0, 1.0, 0.0, 0.0])), Row(probability=DenseVector([0.0, 0.0, 1.0, 0.0, 0.0])), Row(probability=DenseVector([1.0, 0.0, 0.0, 0.0, 0.0])), Row(probability=DenseVector([0.0, 1.0, 0.0, 0.0, 0.0])), Row(probability=DenseVector([1.0, 0.0, 0.0, 0.0, 0.0])), Row(probability=DenseVector([0.0, 0.0, 1.0, 0.0, 0.0])), Row(probability=DenseVector([0.9927, 0.0, 0.0, 0.0, 0.0073])), Row(probability=DenseVector([0.9927, 0.0, 0.0, 0.0, 0.0073]))]\n"
     ]
    }
   ],
   "source": [
    "print(\"Model weights = {}\".format(gmmModel.weights))\n",
    "gmmModel.gaussiansDF.show()\n",
    "gmmModel.summary.cluster.show(10)\n",
    "print(\"Cluster sizes = {}\".format(gmmModel.summary.clusterSizes))\n",
    "print(gmmModel.summary.probability.take(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
