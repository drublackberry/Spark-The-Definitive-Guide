{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.master(\"local\").appName(\"Chapter27-sample\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_raw_df = spark.read.format(\"csv\").option(\"header\", \"true\")\\\n",
    "                                   .option(\"inferSchema\", \"true\")\\\n",
    "                                   .option(\"path\", \"../data/extra-data/kaggle-housing/train.csv\")\\\n",
    "                                   .load().coalesce(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "VERBOSE = False\n",
    "LIMIT_FEATURES = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering\n",
    "\n",
    "The following steps are taken\n",
    "\n",
    "* Replace the strings containing number characters (e.g. '1', '2'...) by the reading form (e.g. 'one')\n",
    "* Select some features, in two steps:\n",
    "    * Use only those features which are continuous (e.g. data type is integer in the dataset).\n",
    "    * Hard limit the number of features by user's choice based on value diversity.\n",
    "* Build pyspark's feature estimators and transformers for later pipelininig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in order to use RFormula later on, substitute numbers by words (e.g. 1 by One)\n",
    "translate_dict = {\"1\":\"One\", \"2\":\"Two\", \"3\":\"Three\", \"4\":\"Four\", \"5\":\"Five\"}\n",
    "def fix_number (x):\n",
    "    for k, v in translate_dict.items():\n",
    "        if k in x:\n",
    "            return x.replace(k, v) \n",
    "    return x\n",
    "for col_name in train_raw_df.columns:\n",
    "    train_raw_df = train_raw_df.withColumnRenamed(col_name, fix_number(col_name))\n",
    "\n",
    "if VERBOSE:\n",
    "    train_raw_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for display purposes, and in order not to enter tokenization and one-hot encoding, let's just take integer features\n",
    "col_to_keep = [col_name for col_name, col_type in train_raw_df.dtypes if col_type =='int']\n",
    "train_raw_df = train_raw_df.select(col_to_keep)\n",
    "\n",
    "if VERBOSE:\n",
    "    print(train_raw_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records = 1460\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import countDistinct, col, isnull\n",
    "import pandas as pd\n",
    "\n",
    "print(\"Number of records = {}\".format(train_raw_df.count()))\n",
    "\n",
    "spec_df = pd.DataFrame(index=train_raw_df.columns, columns=[\"distinct_values\", \"missing_values\"])\n",
    "for c in train_raw_df.columns: \n",
    "    spec_df.loc[c, \"distinct_values\"] = train_raw_df.agg(countDistinct(c).alias(\"count_distinct\")).collect()[0].count_distinct\n",
    "    spec_df.loc[c, \"missing_values\"] = train_raw_df.select(isnull(c).alias(\"is_null\")).where(col(\"is_null\")).count()\n",
    "spec_df = spec_df.sort_values(by=\"distinct_values\", ascending=False)\n",
    "\n",
    "if VERBOSE: \n",
    "    print(spec_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit the number of features by selecting the ones with a bigger spectre.\n",
    "num_features = spec_df.shape[0] if LIMIT_FEATURES is None else LIMIT_FEATURES\n",
    "features_to_use = spec_df[(spec_df.index!='Id') & (spec_df.index!='SalePrice')].iloc[:num_features].index.values\n",
    "\n",
    "if VERBOSE:\n",
    "    print(\"Using features: {}\".format(features_to_use))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build pyspark's transformers and estimators\n",
    "from pyspark.ml.feature import RFormula, StandardScaler\n",
    "\n",
    "rForm = RFormula(formula=\"Saleprice ~ \" + \" + \".join(features_to_use))\n",
    "std_scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\")\n",
    "feature_transformers = [rForm, std_scaler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classic train-test split. Note that only train_df will be used for cross-val \n",
    "train_df, test_df = train_raw_df.randomSplit([0.8, 0.2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression (straight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 for train data = 0.8089736349555801\n",
      "R2 for test data = 0.7926925891268555\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.pipeline import Pipeline\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# estimator pipeline\n",
    "lr_model = LinearRegression(featuresCol=\"scaledFeatures\", labelCol=\"SalePrice\", standardization=False, maxIter=100)\n",
    "pipe = Pipeline()\n",
    "pipe.setStages([*feature_transformers, lr_model])\n",
    "\n",
    "# evaluator\n",
    "reg_eval = RegressionEvaluator(labelCol=\"SalePrice\", metricName=\"r2\")\n",
    "\n",
    "# check that the pipe works\n",
    "pipe_fitted = pipe.fit(train_df)\n",
    "print(\"R2 for train data = {}\".format(reg_eval.evaluate(pipe_fitted.transform(train_df))))\n",
    "print(\"R2 for test data = {}\".format(reg_eval.evaluate(pipe_fitted.transform(test_df))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param grid\n",
    "grid = ParamGridBuilder().addGrid(lr_model.regParam, [0., 1e-3, 0.1, 1., 10., 100.])\\\n",
    "                         .addGrid(lr_model.elasticNetParam, [0., 1e-3, 0.5, 1.]).build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data: R2 = 0.808916040160577, log(R2) = -0.21206014955837327\n",
      "Test data: R2 = 0.7933432591458462, log(R2) = -0.23149928953461726\n"
     ]
    }
   ],
   "source": [
    "# this cell is isolated so it can be called back again stand-alone to derive performance\n",
    "import numpy as np\n",
    "\n",
    "#tvs\n",
    "tvs = TrainValidationSplit().setTrainRatio(0.8)\\\n",
    "                            .setEstimatorParamMaps(grid)\\\n",
    "                            .setEstimator(pipe)\\\n",
    "                            .setEvaluator(reg_eval)\n",
    "tvs_fitted = tvs.fit(train_df)\n",
    "\n",
    "# evaluation\n",
    "for ds_name, ds in {\"Train\": train_df, \"Test\": test_df}.items():\n",
    "    r2_val = reg_eval.evaluate(tvs_fitted.transform(ds))\n",
    "    print(\"{} data: R2 = {}, log(R2) = {}\".format(ds_name, r2_val, np.log(r2_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best regularization param = 100.0\n",
      "Best elastic net param = 1.0\n"
     ]
    }
   ],
   "source": [
    "# this cell is specific to the regressor, hence can't be called back by other regressor types\n",
    "# as per bug, getParam() does not work and java object below needs to be accessed.\n",
    "best_reg = tvs_fitted.bestModel.stages[2]._java_obj.getRegParam()\n",
    "print(\"Best regularization param = {}\".format(best_reg))\n",
    "\n",
    "best_en = tvs_fitted.bestModel.stages[2]._java_obj.getElasticNetParam()\n",
    "print(\"Best elastic net param = {}\".format(best_en))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CART (Decision Trees for regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 for train data = 0.8597456165696578\n",
      "R2 for test data = 0.6546036932394312\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import DecisionTreeRegressor\n",
    "\n",
    "dtr_model = DecisionTreeRegressor(featuresCol=\"scaledFeatures\", labelCol=\"SalePrice\")\n",
    "pipe = Pipeline()\n",
    "pipe.setStages([*feature_transformers, dtr_model])\n",
    "\n",
    "# check that the pipe works\n",
    "pipe_fitted = pipe.fit(train_df)\n",
    "print(\"R2 for train data = {}\".format(reg_eval.evaluate(pipe_fitted.transform(train_df))))\n",
    "print(\"R2 for test data = {}\".format(reg_eval.evaluate(pipe_fitted.transform(test_df))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Executing: ===\n",
      "# this cell is isolated so it can be called back again stand-alone to derive performance\n",
      "import numpy as np\n",
      "\n",
      "#tvs\n",
      "tvs = TrainValidationSplit().setTrainRatio(0.8)\\\n",
      "                            .setEstimatorParamMaps(grid)\\\n",
      "                            .setEstimator(pipe)\\\n",
      "                            .setEvaluator(reg_eval)\n",
      "tvs_fitted = tvs.fit(train_df)\n",
      "\n",
      "# evaluation\n",
      "for ds_name, ds in {\"Train\": train_df, \"Test\": test_df}.items():\n",
      "    r2_val = reg_eval.evaluate(tvs_fitted.transform(ds))\n",
      "    print(\"{} data: R2 = {}, log(R2) = {}\".format(ds_name, r2_val, np.log(r2_val)))\n",
      "=== Output: ===\n",
      "Train data: R2 = 0.9330720194788542, log(R2) = -0.06927288981822431\n",
      "Test data: R2 = 0.5731148550822822, log(R2) = -0.5566691371840694\n"
     ]
    }
   ],
   "source": [
    "# param grid\n",
    "grid = ParamGridBuilder().addGrid(dtr_model.maxDepth, [4, 5, 6, 7])\\\n",
    "                         .addGrid(dtr_model.maxBins, [24, 32, 48, 64]).build()\n",
    "%rerun 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 for train data = 0.8910637983284904\n",
      "R2 for test data = 0.7932206390576011\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "\n",
    "rf_model = RandomForestRegressor(featuresCol=\"scaledFeatures\", labelCol=\"SalePrice\")\n",
    "pipe = Pipeline()\n",
    "pipe.setStages([*feature_transformers, rf_model])\n",
    "\n",
    "# check that the pipe works\n",
    "pipe_fitted = pipe.fit(train_df)\n",
    "print(\"R2 for train data = {}\".format(reg_eval.evaluate(pipe_fitted.transform(train_df))))\n",
    "print(\"R2 for test data = {}\".format(reg_eval.evaluate(pipe_fitted.transform(test_df))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Executing: ===\n",
      "# this cell is isolated so it can be called back again stand-alone to derive performance\n",
      "import numpy as np\n",
      "\n",
      "#tvs\n",
      "tvs = TrainValidationSplit().setTrainRatio(0.8)\\\n",
      "                            .setEstimatorParamMaps(grid)\\\n",
      "                            .setEstimator(pipe)\\\n",
      "                            .setEvaluator(reg_eval)\n",
      "tvs_fitted = tvs.fit(train_df)\n",
      "\n",
      "# evaluation\n",
      "for ds_name, ds in {\"Train\": train_df, \"Test\": test_df}.items():\n",
      "    r2_val = reg_eval.evaluate(tvs_fitted.transform(ds))\n",
      "    print(\"{} data: R2 = {}, log(R2) = {}\".format(ds_name, r2_val, np.log(r2_val)))\n",
      "=== Output: ===\n",
      "Train data: R2 = 0.9033355676481256, log(R2) = -0.10166118036834987\n",
      "Test data: R2 = 0.7613624849701452, log(R2) = -0.2726457073664021\n"
     ]
    }
   ],
   "source": [
    "# param grid\n",
    "grid = ParamGridBuilder().addGrid(rf_model.maxDepth, [4, 5, 6, 7])\\\n",
    "                         .addGrid(rf_model.maxBins, [24, 32, 48, 64])\\\n",
    "                         .addGrid(rf_model.numTrees, [2, 3, 4, 5]).build()\n",
    "%rerun 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating a submission\n",
    "\n",
    "We will use the best estimator to form a prediction of the price of the houses. It will demonstrate how to use the pipeline to predict the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- WoodDeckSF: integer (nullable = true)\n",
      " |-- MoSold: integer (nullable = true)\n",
      " |-- YearBuilt: integer (nullable = true)\n",
      " |-- YearRemodAdd: integer (nullable = true)\n",
      " |-- OverallCond: integer (nullable = true)\n",
      " |-- GrLivArea: integer (nullable = true)\n",
      " |-- EnclosedPorch: integer (nullable = true)\n",
      " |-- Fireplaces: integer (nullable = true)\n",
      " |-- PoolArea: integer (nullable = true)\n",
      " |-- MSSubClass: integer (nullable = true)\n",
      " |-- KitchenAbvGr: integer (nullable = true)\n",
      " |-- LotArea: integer (nullable = true)\n",
      " |-- ScreenPorch: integer (nullable = true)\n",
      " |-- BedroomAbvGr: integer (nullable = true)\n",
      " |-- ThreeSsnPorch: integer (nullable = true)\n",
      " |-- HalfBath: integer (nullable = true)\n",
      " |-- OpenPorchSF: integer (nullable = true)\n",
      " |-- FullBath: integer (nullable = true)\n",
      " |-- MiscVal: integer (nullable = true)\n",
      " |-- TwondFlrSF: integer (nullable = true)\n",
      " |-- OnestFlrSF: integer (nullable = true)\n",
      " |-- YrSold: integer (nullable = true)\n",
      " |-- Id: integer (nullable = true)\n",
      " |-- LowQualFinSF: integer (nullable = true)\n",
      " |-- OverallQual: integer (nullable = true)\n",
      " |-- TotRmsAbvGrd: integer (nullable = true)\n",
      " |-- TotalBsmtSF: integer (nullable = true)\n",
      " |-- GarageCars: integer (nullable = true)\n",
      " |-- BsmtFinSFTwo: integer (nullable = true)\n",
      " |-- GarageArea: integer (nullable = true)\n",
      " |-- BsmtUnfSF: integer (nullable = true)\n",
      " |-- BsmtFullBath: integer (nullable = true)\n",
      " |-- BsmtFinSFOne: integer (nullable = true)\n",
      " |-- BsmtHalfBath: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_raw_df = spark.read.format(\"csv\").option(\"header\", \"true\")\\\n",
    "                                   .option(\"inferSchema\", \"true\")\\\n",
    "                                   .option(\"path\", \"../data/extra-data/kaggle-housing/test.csv\")\\\n",
    "                                   .load().coalesce(5)\n",
    "for col_name in test_raw_df.columns:\n",
    "    test_raw_df = test_raw_df.withColumnRenamed(col_name, fix_number(col_name))\n",
    "test_raw_df = test_raw_df.select(list(set(train_df.columns) - set(['SalePrice'])))\n",
    "\n",
    "# correct for schema inteference mistakes\n",
    "for col_name, col_type in test_raw_df.dtypes:\n",
    "    if col_type == 'string':\n",
    "        # that's an error in the schema inference, cast to int\n",
    "        test_raw_df = test_raw_df.select(*[x for x in test_raw_df.columns if x != col_name], col(col_name).cast('int'))\n",
    "# ensure filling of nulls\n",
    "test_raw_df = test_raw_df.fillna(0)\n",
    "test_raw_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Executing: ===\n",
      "from pyspark.ml.pipeline import Pipeline\n",
      "from pyspark.ml.regression import LinearRegression\n",
      "from pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit\n",
      "from pyspark.ml.evaluation import RegressionEvaluator\n",
      "\n",
      "# estimator pipeline\n",
      "lr_model = LinearRegression(featuresCol=\"scaledFeatures\", labelCol=\"SalePrice\", standardization=False, maxIter=100)\n",
      "pipe = Pipeline()\n",
      "pipe.setStages([*feature_transformers, lr_model])\n",
      "\n",
      "# evaluator\n",
      "reg_eval = RegressionEvaluator(labelCol=\"SalePrice\", metricName=\"r2\")\n",
      "\n",
      "# check that the pipe works\n",
      "pipe_fitted = pipe.fit(train_df)\n",
      "print(\"R2 for train data = {}\".format(reg_eval.evaluate(pipe_fitted.transform(train_df))))\n",
      "print(\"R2 for test data = {}\".format(reg_eval.evaluate(pipe_fitted.transform(test_df))))\n",
      "=== Output: ===\n",
      "R2 for train data = 0.8089736349555801\n",
      "R2 for test data = 0.7926925891268555\n",
      "=== Executing: ===\n",
      "# param grid\n",
      "grid = ParamGridBuilder().addGrid(lr_model.regParam, [0., 1e-3, 0.1, 1., 10., 100.])\\\n",
      "                         .addGrid(lr_model.elasticNetParam, [0., 1e-3, 0.5, 1.]).build()\n",
      "=== Output: ===\n",
      "=== Executing: ===\n",
      "# this cell is isolated so it can be called back again stand-alone to derive performance\n",
      "import numpy as np\n",
      "\n",
      "#tvs\n",
      "tvs = TrainValidationSplit().setTrainRatio(0.8)\\\n",
      "                            .setEstimatorParamMaps(grid)\\\n",
      "                            .setEstimator(pipe)\\\n",
      "                            .setEvaluator(reg_eval)\n",
      "tvs_fitted = tvs.fit(train_df)\n",
      "\n",
      "# evaluation\n",
      "for ds_name, ds in {\"Train\": train_df, \"Test\": test_df}.items():\n",
      "    r2_val = reg_eval.evaluate(tvs_fitted.transform(ds))\n",
      "    print(\"{} data: R2 = {}, log(R2) = {}\".format(ds_name, r2_val, np.log(r2_val)))\n",
      "=== Output: ===\n",
      "Train data: R2 = 0.808916040160577, log(R2) = -0.21206014955837327\n",
      "Test data: R2 = 0.7933432591458462, log(R2) = -0.23149928953461726\n"
     ]
    }
   ],
   "source": [
    "%rerun 10\n",
    "%rerun 11\n",
    "%rerun 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = tvs_fitted.transform(test_raw_df).select(col(\"Id\"), col(\"prediction\").alias(\"SalePrice\"))\n",
    "submission_df.write.format(\"csv\")\\\n",
    "             .mode(\"overwrite\").option(\"sep\", \",\")\\\n",
    "             .save(\"../data/extra-data/kaggle-housing/test_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
